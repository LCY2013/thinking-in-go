[官方地址](https://docs.flagger.app/tutorials/istio-progressive-delivery)

### 灰度发布过程
![灰度发布过程](image/灰度发布过程.png)

### 自动化灰度发布 - Flagger
![自动化灰度发布 - Flagger](image/自动化灰度发布-Flagger.png)

- 自动灰度发布工具
- 支持多种 Service Mesh
  - Istio
  - Linkerd
  - App AWS Mesh
- 指标监控灰度发布状态
- 通知(slack、Microsoft team)

### Flagger 工作流程
![Flagger 工作流程](image/Flagger工作流程.png)

#### 状态
- Initializing
- Initialized
- Progressing
- Succeeded(failed)

### 准备工作
- Flagger 安装 
  - Repo
  - CRDs
  - 部署
- Slack 通知 (可选)

### 演示
- 应用部署 
- 灰度配置 
- 测试

### 配置分析
![自动灰度发布配置分析](image/自动灰度发布配置分析.png)

- 配置灰度发布策略，触发回滚逻辑
- 提示:使用 httpbin 的 status/500 或者 delay 接口触发失败阈值

### Order
- 确保系统存在k8s、istio等...

- 在demo命名空间中创建sleep、httpbin两个项目（istio项目/samples/httpbin/httpbin.yaml、istio项目/samples/sleep/sleep.yaml）

- [helm 安装文档](https://helm.sh/zh/docs/intro/install/)

- add repo
> helm repo add flagger https://flagger.app

- install crd
> kubectl apply -f https://raw.githubusercontent.com/weaveworks/flagger/master/artifacts/flagger/crd.yaml

- 查询flagger CRD信息
> kubectl get crd | grep flagger

- 探测 prometheus 在 istio 中是否存在, sleep 部署可以见 istio 官方demo
> kubectl exec -n demo -it sleep-854565cb79-zdrj4 -c sleep -- curl "http://prometheus.istio-system:9090"

- 部署flagger with istio
```shell
helm upgrade -i flagger flagger/flagger \
--namespace=istio-system \
--set crd.create=false \
--set meshProvider=istio \
--set metricsServer=http://prometheus.istio-system:9090
```

- slack 可选项
  - [slack](https://api.slack.com/messaging/webhooks)
  - [slack new app](https://api.slack.com/apps?new_app=1)
```shell
helm upgrade -i flagger flagger/flagger \
--namespace=istio-system \
--set crd.create=false \
--set slack.url=https://hooks.slack.com/services/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 \
--set slack.channel=luochunyun1995 \
--set slack.user=luochunyun1995
```

- 探测 prometheus 在 istio 中是否存在, sleep 部署可以见 istio 官方demo
> kubectl exec -n demo -it sleep-854565cb79-zdrj4 -c sleep -- curl "http://grafana.istio-system:3000"

- grafana
```shell
helm upgrade -i flagger-grafana flagger/grafana \
--namespace=istio-system \
--set url=http://prometheus.istio-system:9090 \
--set user=admin \
--set password=change-me
```
```text
NAME: flagger-grafana
LAST DEPLOYED: Wed Jun 16 11:53:38 2021
NAMESPACE: istio-system
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
1. Run the port forward command:

kubectl -n istio-system port-forward svc/flagger-grafana 3000:80

2. Navigate to:

http://localhost:3000
```

- 查看flagger的部署情况
> kubectl get po -n istio-system
 
#### 部署flagger另一种方式,或者下载repo直接执行
> kubectl apply -k github.com/weaveworks/flagger//kustomize/istio

- ingress for expose mesh
```yaml
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: public-gateway
  namespace: istio-system
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http
        protocol: HTTP
      hosts:
        - "*"
```

- 部署应用和tester
> kubectl apply -k github.com/weaveworks/flagger//kustomize/tester

- 或者 先clone repo
> k apply -f deployment.yaml -n demo

> k apply -f service.yaml -n demo

- 查询负载测试工具
> kubectl get po -n test | grep tester

- 添加hpa
```yaml
k apply -n demo -f - <<EOF
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: httpbin
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: httpbin
  minReplicas: 2
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: cpu
      # scale up if usage is above
      # 99% of the requested CPU (100m)
      targetAverageUtilization: 99
EOF
```

- 创建 canary 分析
```yaml
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: httpbin
  namespace: demo
spec:
  # deployment reference
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: httpbin
  # the maximum time in seconds for the canary deployment
  # to make progress before it is rollback (default 600s)
  progressDeadlineSeconds: 60
  # HPA reference (optional)
  autoscalerRef:
    apiVersion: autoscaling/v2beta1
    kind: HorizontalPodAutoscaler
    name: httpbin
  service:
    # service port number
    port: 8000
    # container port number or name (optional)
    targetPort: 80
    # Istio gateways (optional)
    gateways:
    - public-gateway.istio-system.svc.cluster.local
  analysis:
    # schedule interval (default 60s)
    interval: 30s
    # max number of failed metric checks before rollback
    threshold: 5
    # max traffic percentage routed to canary
    # percentage (0-100)
    maxWeight: 100
    # canary increment step
    # percentage (0-100)
    stepWeight: 20
    metrics:
    - name: request-success-rate
      # minimum req success rate (non 5xx responses)
      # percentage (0-100)
      thresholdRange:
        min: 99
      interval: 1m
    - name: latency
      templateRef:
        name: latency
        namespace: istio-system
      # maximum req duration P99
      # milliseconds
      thresholdRange:
        max: 500
      interval: 30s
    # testing (optional)
    webhooks:
      - name: load-test
        url: http://flagger-loadtester.test/
        timeout: 5s
        metadata:
          cmd: "hey -z 1m -q 10 -c 2 http://httpbin-canary.demo:8000/headers"
```

- 查询canary
> kubectl get canary -n demo

> kubectl get all -n demo

> kubectl get vs -n demo

- 创建metric for 1.5
```yaml
k apply -f - <<EOF
apiVersion: flagger.app/v1beta1
kind: MetricTemplate
metadata:
  name: latency
  namespace: istio-system
spec:
  provider:
    type: prometheus
    address: http://prometheus.istio-system:9090
  query: |
    histogram_quantile(
        0.99,
        sum(
            rate(
                istio_request_duration_milliseconds_bucket{
                    reporter="destination",
                    destination_workload_namespace="{{ namespace }}",
                    destination_workload=~"{{ target }}"
                }[{{ interval }}]
            )
        ) by (le)
    )
EOF
```

- 触发灰度, dep/configmap/secret 都会触发
> kubectl -n demo set image deployment/httpbin httpbin=httpbin-v2

- 循环访问
> kubectl exec -it -n demo pod/sleep-854565cb79-zdrj4 -c sleep sh 
while [ 1 ]; do curl http://httpbin.demo:8000/headers;sleep 2s; done

- 开始后查看Virtual Service
> kubectl describe vs httpbin -n demo